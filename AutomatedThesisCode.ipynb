{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f907827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "path = 'C:\\\\Users\\\\mrgba\\\\OneDrive\\\\Thesis\\\\ThesisData\\\\RawData\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "419830a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation metrics\n",
    "def MAPE(test_y, pred_y): \n",
    "    test_y, pred_y = np.array(test_y), np.array(pred_y)\n",
    "    return np.mean(np.abs((test_y - pred_y) / test_y)) * 100\n",
    "\n",
    "# model must be fit on training data before using evaluate\n",
    "def evaluate(model, test_x, test_y):\n",
    "    pred_y = model.predict(test_x)\n",
    "    rmse = MSE(test_y, pred_y, squared = False)\n",
    "    mape = MAPE(test_y, pred_y)\n",
    "    pearson = pearsonr(test_y, pred_y)\n",
    "    spearman = spearmanr(test_y, pred_y)\n",
    "    return rmse, mape, pearson, spearman, pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f328334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists of things to be iterated through for each loop\n",
    "\n",
    "# LOOP 1\n",
    "# outermost loop iterates through all four different prediction methods\n",
    "methods = ['M1', 'M2', 'M3', 'M4']\n",
    "\n",
    "# LOOP 2\n",
    "# next loop iterates through allowing the use of aircraft data or not.\n",
    "# allowing aircraft data will be denoted as 'all', where not allowing it\n",
    "# will only use subject-related features, denoted as 'subj'\n",
    "datatype = ['all', 'subj']\n",
    "\n",
    "# LOOP 3\n",
    "# next loop iterates through all four different types of models being compared\n",
    "# RandomForest = 'rf', ExtraTrees = 'xt', XGBoost = 'xgb', CategoricalBoosting = 'cb'\n",
    "modeltype = ['rf', 'xt', 'xgb', 'cb']\n",
    "\n",
    "# also need a list of dictionaries, where each dictionary is the different hyperparameters\n",
    "# to be explored through the cross-validated grid search\n",
    "hyperparameters = [\n",
    "    # RandomForest Hyperparameters\n",
    "    {'bootstrap': [False, True],\n",
    "     'max_depth' : [2,3,4,5,6,7,None],\n",
    "     'min_samples_leaf': [1,2,3,4,5,6],\n",
    "     'min_samples_split': [2,3,4,5,6,7],\n",
    "     'n_estimators': [10,25,50,100,150,200]}, \n",
    "    # ExtraTrees Hyperparameters\n",
    "    {'n_estimators' : [10,25,50,100,150,200],\n",
    "     'max_depth' : [2,3,4,5,6,None],\n",
    "     'min_samples_split' : [2,3,4,5,6,7],\n",
    "     'min_samples_leaf' : [1,2,3,4,5,6],\n",
    "     'bootstrap' : [True, False]},\n",
    "    # XGBoost Hyperparameters\n",
    "    {'max_depth': [2,3,4,5,6,7,None],\n",
    "     'n_estimators': [10,25,50,100,150,200],\n",
    "     'colsample_bytree': [0.1,0.15,0.2,0.25,.3,0.4,0.5],\n",
    "     'booster' : ['gbtree','dart']},\n",
    "    # CatBoost Hyperparameters\n",
    "    {'depth': [2,3,4,5],\n",
    "     'l2_leaf_reg' : [2,6,4,8,10],\n",
    "     'learning_rate' : [0.01,0.02,0.03,0.04,0.05],\n",
    "     'min_child_samples' : [1,2,4,6,8]}\n",
    "]\n",
    "\n",
    "# LOOP 4\n",
    "# next loop performs 10 repetitions of each model, where the list is different random seeds\n",
    "seeds = [42, 4, 32, 2, 7, 2021, 2013, 97, 835, 13]\n",
    "\n",
    "# need a list of the different error types to be pulled for Y data\n",
    "errortype = ['Cumulative_Error', 'GlideSlope_Error', 'Localizer_Error', 'Airspeed_Error']\n",
    "# with respect to each error source above, need a list of lists of all candidate values to be explored.\n",
    "# conservatively took the min/max of each error source, building a dense candidate list of every 100 between them\n",
    "candidates = [np.arange(700, 12100, 100).tolist(), # Cumulative Error candidates values\n",
    "              np.arange(100, 5100, 100).tolist(), # GlideSlope Error candidates values\n",
    "              np.arange(0, 6100, 100).tolist(), # Localizer Error candidates values\n",
    "              np.arange(100, 5100, 100).tolist()] # Airspeed Error candidates values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "000fcd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary functions for operational use in code\n",
    "\n",
    "def DATASORT(data_type, method):\n",
    "    \n",
    "    x_train = pd.read_csv(path+'trainX_all.csv')\n",
    "    x_test = pd.read_csv(path+'testX_all.csv')\n",
    "    features = pd.read_csv(path+'selected_features.csv')\n",
    "    \n",
    "    if method == 'M1':\n",
    "        # only need features selected for cumulative error for these two methods\n",
    "        if data_type == 'subj':\n",
    "            # need to remove NaNs from column\n",
    "            feats = list(features['subj_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train = x_train[cleanedList]\n",
    "            x_test = x_test[cleanedList]    \n",
    "        else:\n",
    "            feats = list(features['all_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train = x_train[cleanedList]\n",
    "            x_test = x_test[cleanedList]\n",
    "        \n",
    "        return x_train, x_test\n",
    "    \n",
    "    elif method == 'M3':\n",
    "        # need to get all unique features selected for the three individual error sources\n",
    "        if data_type == 'subj':\n",
    "            # need to remove NaNs from column\n",
    "            feats1 = list(features['subj_GlideSlope_Error_Features'].values)\n",
    "            feats2 = list(features['subj_Localizer_Error_Features'].values)\n",
    "            feats3 = list(features['subj_Airspeed_Error_Features'].values)\n",
    "            feats = feats1+feats2+feats3\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            # remove duplicates\n",
    "            cleanerList = [*set(cleanedList)]\n",
    "            x_train = x_train[cleanerList]\n",
    "            x_test = x_test[cleanerList]    \n",
    "        else:\n",
    "            feats1 = list(features['all_GlideSlope_Error_Features'].values)\n",
    "            feats2 = list(features['all_Localizer_Error_Features'].values)\n",
    "            feats3 = list(features['all_Airspeed_Error_Features'].values)\n",
    "            feats = feats1+feats2+feats3\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            # remove duplicates\n",
    "            cleanerList = [*set(cleanedList)]\n",
    "            x_train = x_train[cleanerList]\n",
    "            x_test = x_test[cleanerList] \n",
    "        \n",
    "        return x_train, x_test\n",
    "    \n",
    "    # though same dataset for method 4, returning multiple to match formatting for model training/combination    \n",
    "    elif method == 'M4':\n",
    "        if data_type == 'subj':\n",
    "            # GlideSlope\n",
    "            feats = list(features['subj_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_g = x_train[cleanedList]\n",
    "            x_test_g = x_test[cleanedList]\n",
    "            # Localizer\n",
    "            feats = list(features['subj_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_l = x_train[cleanedList]\n",
    "            x_test_l = x_test[cleanedList]\n",
    "            # Airspeed\n",
    "            feats = list(features['subj_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_a = x_train[cleanedList]\n",
    "            x_test_a = x_test[cleanedList]\n",
    "        else:\n",
    "            # GlideSlope\n",
    "            feats = list(features['all_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_g = x_train[cleanedList]\n",
    "            x_test_g = x_test[cleanedList]\n",
    "            # Localizer\n",
    "            feats = list(features['all_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_l = x_train[cleanedList]\n",
    "            x_test_l = x_test[cleanedList]\n",
    "            # Airspeed\n",
    "            feats = list(features['all_Cumulative_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_a = x_train[cleanedList]\n",
    "            x_test_a = x_test[cleanedList] \n",
    "        \n",
    "        return x_train_g, x_test_g, x_train_l, x_test_l, x_train_a, x_test_a\n",
    "        \n",
    "        \n",
    "    # finally, method 2 datasets\n",
    "    else:\n",
    "        # M2\n",
    "        if data_type == 'subj':\n",
    "            # GlideSlope\n",
    "            feats = list(features['subj_GlideSlope_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_g = x_train[cleanedList]\n",
    "            x_test_g = x_test[cleanedList]\n",
    "            # Localizer\n",
    "            feats = list(features['subj_Localizer_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_l = x_train[cleanedList]\n",
    "            x_test_l = x_test[cleanedList]\n",
    "            # Airspeed\n",
    "            feats = list(features['subj_Airspeed_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_a = x_train[cleanedList]\n",
    "            x_test_a = x_test[cleanedList]\n",
    "        else:\n",
    "            # GlideSlope\n",
    "            feats = list(features['all_GlideSlope_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_g = x_train[cleanedList]\n",
    "            x_test_g = x_test[cleanedList]\n",
    "            # Localizer\n",
    "            feats = list(features['all_Localizer_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_l = x_train[cleanedList]\n",
    "            x_test_l = x_test[cleanedList]\n",
    "            # Airspeed\n",
    "            feats = list(features['all_Airspeed_Error_Features'].values)\n",
    "            cleanedList = [x for x in feats if str(x) != 'nan']\n",
    "            x_train_a = x_train[cleanedList]\n",
    "            x_test_a = x_test[cleanedList] \n",
    "        \n",
    "        return x_train_g, x_test_g, x_train_l, x_test_l, x_train_a, x_test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c1f78b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for transductive conformal prediction\n",
    "\n",
    "def TCP(x_train, x_test, y_train, y_test, cand_list, model, alpha):\n",
    "    \n",
    "    coverage_count = 0\n",
    "    width = []\n",
    "    lower = []\n",
    "    upper = []\n",
    "    \n",
    "    g = 0\n",
    "\n",
    "    while g < len(x_test):\n",
    "\n",
    "        # pull row of data points, append to training data set\n",
    "        x_nplus_1 = x_test.iloc[g:g+1,:]\n",
    "        x_train_agg = pd.concat([x_train, x_nplus_1], ignore_index = True)\n",
    "\n",
    "        z = 0\n",
    "        vals_in_interval = []\n",
    "        # iterate through all candidate values\n",
    "\n",
    "        while z < len(cand_list):\n",
    "\n",
    "            # pull candidate value and append it to y values\n",
    "            y_c = pd.Series([cand_list[z]],index=[0])\n",
    "            y_train_agg = pd.concat([y_train, y_c], ignore_index = True)\n",
    "\n",
    "            new_model = model\n",
    "\n",
    "            new_model = new_model.fit(x_train_agg, y_train_agg)\n",
    "            preds = new_model.predict(x_train_agg)\n",
    "\n",
    "            conformity_scores = abs(y_train_agg - preds)\n",
    "\n",
    "            r_nplus_1 = conformity_scores.loc[len(conformity_scores)-1]\n",
    "            indicator_func = ((conformity_scores <= r_nplus_1).astype(int)).sum() - 1\n",
    "            pi_y_nplus_1 = (1/len(y_train_agg)) + ((1/len(y_train_agg))*indicator_func)\n",
    "\n",
    "            if (len(y_train_agg)*pi_y_nplus_1) <= math.ceil((1-alpha)*len(y_train_agg)):\n",
    "                vals_in_interval.append(cand_list[z])\n",
    "\n",
    "            z += 1\n",
    "\n",
    "        width.append(max(vals_in_interval) - min(vals_in_interval))\n",
    "        \n",
    "        if (y_test.iloc[g] <= max(vals_in_interval)) and (y_test.iloc[g] >= min(vals_in_interval)):\n",
    "            coverage_count += 1\n",
    "        lower.append(min(vals_in_interval))\n",
    "        upper.append(max(vals_in_interval))\n",
    "        \n",
    "        g += 1\n",
    "    \n",
    "    avg_pi_width = np.mean(width)\n",
    "    stddev_pi_width = np.std(width)\n",
    "    marg_cov = coverage_count/(len(x_test))\n",
    "    \n",
    "    return avg_pi_width, stddev_pi_width, marg_cov, lower, upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec0e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3024 candidates, totalling 15120 fits\n",
      "Fitting 5 folds for each of 3024 candidates, totalling 15120 fits\n"
     ]
    }
   ],
   "source": [
    "# build large dataframe to handle all results\n",
    "results = pd.DataFrame(columns=['Method','DataType','ErrorSource','ModelType','Iteration',\n",
    "                                'RMSE','MAPE','Pearson','Spearman','AvgPIWidth','StdDevPIWidth',\n",
    "                                'MarginalCoverage','Hyperparameters'])\n",
    "\n",
    "# reading in data for use with aggregation\n",
    "true_cumul = pd.read_csv(path+'testY.csv')[errortype[0]]\n",
    "\n",
    "# begin first loop, all four methods\n",
    "for i in methods:    \n",
    "# begin second loop, all or subj data used\n",
    "    for j in datatype:       \n",
    "# load training/testing data here so that it wont have to be done multiple times in the following loops\n",
    "        if i == 'M1' or i == 'M3':\n",
    "            x_train, x_test = DATASORT(j, i)\n",
    "            y_train = pd.read_csv(path+'trainY.csv')[errortype[0]]\n",
    "            y_test = pd.read_csv(path+'testY.csv')[errortype[0]]\n",
    "        else:\n",
    "            x_train_g, x_test_g, x_train_l, x_test_l, x_train_a, x_test_a = DATASORT(j, i)\n",
    "            y_train_g = pd.read_csv(path+'trainY.csv')[errortype[1]]\n",
    "            y_test_g = pd.read_csv(path+'testY.csv')[errortype[1]]\n",
    "            y_train_l = pd.read_csv(path+'trainY.csv')[errortype[2]]\n",
    "            y_test_l = pd.read_csv(path+'testY.csv')[errortype[2]]\n",
    "            y_train_a = pd.read_csv(path+'trainY.csv')[errortype[3]]\n",
    "            y_test_a = pd.read_csv(path+'testY.csv')[errortype[3]]        \n",
    "# begin third loop, each of the four different models\n",
    "        for k in modeltype:            \n",
    "# begin fourth loop, 10 iterations of the model with different seeds\n",
    "            for l in range(len(seeds)):\n",
    "                if k == 'rf':\n",
    "                    model = RandomForestRegressor(random_state = seeds[l])\n",
    "                    param_grid = hyperparameters[0]    \n",
    "                elif k == 'xt':\n",
    "                    model = ExtraTreesRegressor(random_state = seeds[l])\n",
    "                    param_grid = hyperparameters[1]    \n",
    "                elif k == 'xgb':\n",
    "                    model = xgb.XGBRegressor(objective='reg:squarederror', seed = seeds[l])\n",
    "                    param_grid = hyperparameters[2]\n",
    "                else:\n",
    "                    model = CatBoostRegressor(random_state = seeds[l], verbose=0)\n",
    "                    param_grid = hyperparameters[3]\n",
    "                    \n",
    "                grid_search = GridSearchCV(estimator = model, param_grid = param_grid, \n",
    "                          cv = 5, verbose = 2, n_jobs = -1)\n",
    "                if i == 'M1' or i == 'M3':\n",
    "                    grid_search.fit(x_train, y_train)\n",
    "                    best_parameters = grid_search.best_params_\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    best_model.fit(x_train, y_train)\n",
    "                    rmse, mape, pearson, spearman, pred_y = evaluate(best_model, x_test, y_test)\n",
    "                    \n",
    "                    # Now perform transductive conformal prediction\n",
    "                    avg_pi_width, stddev_pi_width, marg_cov, lower, upper = TCP(x_train, x_test, y_train, y_test,\n",
    "                                                 candidates[0], grid_search.best_estimator_, 0.05)\n",
    "                    \n",
    "                    # finally, add all results to dataframe\n",
    "                    results.loc[len(results)] = [i,j,'Cumulative',k,l+1,\n",
    "                                                 rmse,mape,pearson,spearman,avg_pi_width,stddev_pi_width,\n",
    "                                                 marg_cov,best_parameters]\n",
    "                    \n",
    "                else:\n",
    "                    # Need aggregated techniques for methods 2 and 4\n",
    "                    # GlideSlope Error\n",
    "                    grid_search.fit(x_train_g, y_train_g)\n",
    "                    best_parameters = grid_search.best_params_\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    best_model.fit(x_train_g, y_train_g)\n",
    "                    rmse, mape, pearson, spearman, pred_y_g = evaluate(best_model, x_test_g, y_test_g)\n",
    "                    \n",
    "                    # Now perform transductive conformal prediction\n",
    "                    avg_pi_width, stddev_pi_width, marg_cov, lower_g, upper_g = TCP(x_train_g, x_test_g, y_train_g, y_test_g,\n",
    "                                                     candidates[1], grid_search.best_estimator_, 0.017)\n",
    "                    \n",
    "                    # finally, add all results to dataframe\n",
    "                    results.loc[len(results)] = [i,j,'GlideSlope',k,l+1,\n",
    "                                                 rmse,mape,pearson,spearman,avg_pi_width,stddev_pi_width,\n",
    "                                                 marg_cov,best_parameters]\n",
    "                    \n",
    "                    # Localizer Error\n",
    "                    grid_search.fit(x_train_l, y_train_l)\n",
    "                    best_parameters = grid_search.best_params_\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    best_model.fit(x_train_l, y_train_l)\n",
    "                    rmse, mape, pearson, spearman, pred_y_l = evaluate(best_model, x_test_l, y_test_l)\n",
    "                    \n",
    "                    # Now perform transductive conformal prediction\n",
    "                    avg_pi_width, stddev_pi_width, marg_cov, lower_l, upper_l = TCP(x_train_l, x_test_l, y_train_l, y_test_l,\n",
    "                                                     candidates[2], grid_search.best_estimator_, 0.017)\n",
    "                    \n",
    "                    # finally, add all results to dataframe\n",
    "                    results.loc[len(results)] = [i,j,'Localizer',k,l+1,\n",
    "                                                 rmse,mape,pearson,spearman,avg_pi_width,stddev_pi_width,\n",
    "                                                 marg_cov,best_parameters]\n",
    "                    \n",
    "                    # Airspeed Error\n",
    "                    grid_search.fit(x_train_a, y_train_a)\n",
    "                    best_parameters = grid_search.best_params_\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    best_model.fit(x_train_a, y_train_a)\n",
    "                    rmse, mape, pearson, spearman, pred_y_a = evaluate(best_model, x_test_a, y_test_a)\n",
    "                    \n",
    "                    # Now perform transductive conformal prediction\n",
    "                    avg_pi_width, stddev_pi_width,\n",
    "                    marg_cov, lower_a, upper_a = TCP(x_train_a, x_test_a, y_train_a, y_test_a,\n",
    "                                                     candidates[3], grid_search.best_estimator_, 0.017)\n",
    "                    \n",
    "                    # finally, add all results to dataframe\n",
    "                    results.loc[len(results)] = [i,j,'Airspeed',k,l+1,\n",
    "                                                 rmse,mape,pearson,spearman,avg_pi_width,stddev_pi_width,\n",
    "                                                 marg_cov,best_parameters]\n",
    "                    \n",
    "                    # Use lower and uppers from individual predictions intervals to combine for aggregated prediction intervals\n",
    "                    \n",
    "                    agg_pred = pred_y_g + pred_y_l + pred_y_a\n",
    "                    agg_lower = lower_g + lower_l + lower_a\n",
    "                    agg_upper = upper_g + upper_l + upper_a\n",
    "                    agg_width = agg_upper - agg_lower\n",
    "                    \n",
    "                    agg_cov_count = 0\n",
    "                    for h in range(len(true_cumul)):\n",
    "                        if true_cumul.iloc[h] <= agg_upper[h] and true_cumul.iloc[h] >= agg_lower[h]:\n",
    "                            agg_cov_count += 1\n",
    "                    marg_cov = agg_cov_count / len(true_cumul)\n",
    "                    avg_pi_width = np.mean(agg_width)\n",
    "                    stddev_pi_width = np.std(agg_width)\n",
    "                    rmse = MSE(agg_pred, agg_pred, squared = False)\n",
    "                    mape = MAPE(agg_pred, agg_pred)\n",
    "                    pearson = pearsonr(agg_pred, agg_pred)\n",
    "                    spearman = spearmanr(agg_pred, agg_pred)\n",
    "                    best_parameters = 'N/A'\n",
    "                    \n",
    "                    # add aggregated results to dataframe for approximated cumulative error\n",
    "                    results.loc[len(results)] = [i,j,'Cumulative',k,l+1,\n",
    "                                                 rmse,mape,pearson,spearman,avg_pi_width,stddev_pi_width,\n",
    "                                                 marg_cov,best_parameters]\n",
    "            print(results)\n",
    "\n",
    "# automation complete! Save finalized results\n",
    "results.to_csv(path+'results.csv', encoding='utf-8', header='true', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
